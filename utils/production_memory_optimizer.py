#!/usr/bin/env python3
"""
Production Memory Optimizer for GoalDiggers Platform
Optimized memory management for production deployment
"""
import gc
import logging
import os
import sys
import time
from typing import Any, Dict, List, Optional, Tuple

import psutil

# Configure logging
if not os.environ.get("PYTEST_CURRENT_TEST"):
    try:
        from utils.logging_config import configure_logging  # type: ignore
        configure_logging()
    except Exception:
        logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ProductionMemoryOptimizer:
    """Production-ready memory optimizer with comprehensive management"""
    
    def __init__(self, target_memory_mb: int = 350, threshold_mb: int = 400):
        """Initialize the memory optimizer with target memory limit
        
        Args:
            target_memory_mb: Target memory usage after optimization
            threshold_mb: Memory threshold to trigger optimization (default: 400MB)
        """
        self.target_memory_mb = target_memory_mb
        self.threshold_mb = threshold_mb  # Only run optimization if above this
        self.current_process = psutil.Process()
        self.optimization_history = []
        self._last_optimization_time = 0
        self._min_optimization_interval = 300  # Don't optimize more than once per 5 minutes
        logger.info(f"ðŸŽ¯ Production Memory Optimizer initialized (target: {target_memory_mb}MB, threshold: {threshold_mb}MB)")
    
    def get_current_memory_usage(self) -> float:
        """Get current memory usage in MB"""
        try:
            memory_info = self.current_process.memory_info()
            return memory_info.rss / 1024 / 1024  # Convert to MB
        except Exception as e:
            logger.warning(f"Memory check failed: {e}")
            return 0.0
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Get comprehensive memory statistics"""
        try:
            memory_info = self.current_process.memory_info()
            memory_percent = self.current_process.memory_percent()
            current_mb = memory_info.rss / 1024 / 1024
            
            return {
                'current_mb': current_mb,
                'rss_mb': current_mb,
                'vms_mb': memory_info.vms / 1024 / 1024,
                'percent': memory_percent,
                'available_mb': psutil.virtual_memory().available / 1024 / 1024,
                'total_mb': psutil.virtual_memory().total / 1024 / 1024,
                'within_target': current_mb <= self.target_memory_mb
            }
        except Exception as e:
            logger.error(f"Failed to get memory stats: {e}")
            return {'current_mb': 0, 'within_target': False}
    
    def clear_streamlit_cache(self) -> float:
        """Clear Streamlit caches to free memory"""
        memory_freed = 0.0
        
        try:
            # Try to clear Streamlit caches if available
            import streamlit as st

            # Clear various Streamlit caches
            if hasattr(st, 'cache_data'):
                st.cache_data.clear()
                memory_freed += 5.0  # Estimate
                
            if hasattr(st, 'cache_resource'):
                st.cache_resource.clear()
                memory_freed += 5.0  # Estimate
                
            # Clear legacy caches
            if hasattr(st, 'legacy_caching'):
                if hasattr(st.legacy_caching, 'clear_cache'):
                    st.legacy_caching.clear_cache()
                    memory_freed += 3.0  # Estimate
                    
        except Exception as e:
            logger.warning(f"Streamlit cache clearing failed: {e}")
            
        return memory_freed
    
    def optimize_dataframes(self) -> float:
        """Optimize pandas DataFrames in memory"""
        memory_freed = 0.0
        
        try:
            import pandas as pd

            # Get all DataFrame objects from garbage collector
            for obj in gc.get_objects():
                if isinstance(obj, pd.DataFrame):
                    try:
                        # Optimize memory usage
                        if hasattr(obj, 'memory_usage'):
                            old_memory = obj.memory_usage(deep=True).sum()
                            
                            # Convert object columns to category where beneficial
                            for col in obj.select_dtypes(include=['object']).columns:
                                if obj[col].nunique() < len(obj) * 0.5:
                                    obj[col] = obj[col].astype('category')
                            
                            # Downcast numeric columns
                            for col in obj.select_dtypes(include=['int']).columns:
                                obj[col] = pd.to_numeric(obj[col], downcast='integer')
                                
                            for col in obj.select_dtypes(include=['float']).columns:
                                obj[col] = pd.to_numeric(obj[col], downcast='float')
                            
                            new_memory = obj.memory_usage(deep=True).sum()
                            memory_freed += max(0, (old_memory - new_memory) / 1024 / 1024)
                            
                    except Exception:
                        continue
                        
        except ImportError:
            pass
        except Exception as e:
            logger.warning(f"DataFrame optimization failed: {e}")
            
        return memory_freed
    
    def clear_module_caches(self) -> float:
        """Clear various module caches"""
        memory_freed = 0.0
        
        try:
            # Clear import cache
            if hasattr(sys, 'path_importer_cache'):
                sys.path_importer_cache.clear()
                memory_freed += 2.0
                
            # Clear function cache if available
            try:
                import functools

                # Clear lru_cache for all cached functions
                for obj in gc.get_objects():
                    if hasattr(obj, 'cache_clear') and callable(getattr(obj, 'cache_clear')):
                        try:
                            obj.cache_clear()
                            memory_freed += 0.5
                        except Exception:
                            continue
            except Exception:
                pass
                
        except Exception as e:
            logger.warning(f"Module cache clearing failed: {e}")
            
        return memory_freed
    
    def aggressive_gc_collection(self) -> float:
        """Perform aggressive garbage collection"""
        memory_before = self.get_current_memory_usage()
        
        try:
            # Multiple rounds of garbage collection
            for generation in [0, 1, 2]:
                collected = gc.collect(generation)
                if collected > 0:
                    logger.debug(f"GC generation {generation}: collected {collected} objects")
            
            # Force full collection
            gc.collect()
            
        except Exception as e:
            logger.warning(f"Garbage collection failed: {e}")
            
        memory_after = self.get_current_memory_usage()
        return max(0, memory_before - memory_after)
    
    def clear_large_objects(self) -> float:
        """Clear large objects from memory"""
        memory_freed = 0.0
        
        try:
            import sys
            objects_to_clear = []
            
            # Find large objects in memory
            for obj in gc.get_objects():
                try:
                    obj_size = sys.getsizeof(obj)
                    if obj_size > 1024 * 1024:  # Objects > 1MB
                        # Check if it's a data structure we can safely clear
                        if hasattr(obj, 'clear') and callable(getattr(obj, 'clear')):
                            if not isinstance(obj, (type, type(sys.modules))):
                                objects_to_clear.append(obj)
                except Exception:
                    continue
            
            # Clear the objects
            for obj in objects_to_clear:
                try:
                    obj.clear()
                    memory_freed += 1.0  # Estimate 1MB per cleared object
                except Exception:
                    continue
                    
        except Exception as e:
            logger.warning(f"Large object clearing failed: {e}")
            
        return memory_freed
    
    def optimize_memory(self, force: bool = False) -> Dict[str, Any]:
        """Main memory optimization routine with intelligent triggering"""
        initial_memory = self.get_current_memory_usage()
        current_time = time.time()
        
        # Skip optimization if memory is below threshold and not forced
        if not force and initial_memory < self.threshold_mb:
            logger.debug(f"ðŸ’¤ Skipping optimization (memory: {initial_memory:.1f}MB < threshold: {self.threshold_mb}MB)")
            return {
                'success': True,
                'skipped': True,
                'reason': 'below_threshold',
                'memory_before': initial_memory,
                'memory_after': initial_memory,
                'freed_mb': 0,
                'optimization_time': 0,
                'steps': []
            }
        
        # Skip if optimized recently (unless forced)
        if not force and (current_time - self._last_optimization_time) < self._min_optimization_interval:
            time_since_last = current_time - self._last_optimization_time
            logger.debug(f"ðŸ’¤ Skipping optimization (optimized {time_since_last:.0f}s ago, min interval: {self._min_optimization_interval}s)")
            return {
                'success': True,
                'skipped': True,
                'reason': 'too_soon',
                'memory_before': initial_memory,
                'memory_after': initial_memory,
                'freed_mb': 0,
                'optimization_time': 0,
                'steps': []
            }
        
        start_time = time.time()
        logger.info(f"ðŸ”§ Starting memory optimization (current: {initial_memory:.1f}MB)")
        
        total_freed = 0.0
        optimization_steps = []
        
        try:
            # Step 1: Aggressive garbage collection (do this first)
            freed = self.aggressive_gc_collection()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"Initial GC: {freed:.1f}MB")
            
            # Step 2: Clear large objects
            freed = self.clear_large_objects()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"Large objects: {freed:.1f}MB")
            
            # Step 3: Clear Streamlit caches
            freed = self.clear_streamlit_cache()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"Streamlit caches: {freed:.1f}MB")
            
            # Step 4: Optimize DataFrames
            freed = self.optimize_dataframes()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"DataFrame optimization: {freed:.1f}MB")
            
            # Step 5: Clear module caches
            freed = self.clear_module_caches()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"Module caches: {freed:.1f}MB")
            
            # Step 6: Final aggressive garbage collection
            freed = self.aggressive_gc_collection()
            total_freed += freed
            if freed > 0:
                optimization_steps.append(f"Final GC: {freed:.1f}MB")
            
            # If still over target and forced, be more aggressive
            current_memory = self.get_current_memory_usage()
            if force and current_memory > self.target_memory_mb:
                # Force more aggressive cleanup
                import sys

                # Clear more caches
                if hasattr(sys, 'path_hooks'):
                    sys.path_hooks.clear()
                    
                if hasattr(sys, 'meta_path'):
                    # Keep essential importers
                    essential_importers = sys.meta_path[:3]
                    sys.meta_path.clear()
                    sys.meta_path.extend(essential_importers)
                
                # Additional GC cycles
                for _ in range(5):
                    collected = gc.collect()
                    if collected == 0:
                        break
                
                freed = max(0, current_memory - self.get_current_memory_usage())
                total_freed += freed
                if freed > 0:
                    optimization_steps.append(f"Aggressive cleanup: {freed:.1f}MB")
            
        except Exception as e:
            logger.error(f"Memory optimization error: {e}")
        
        final_memory = self.get_current_memory_usage()
        actual_freed = max(0, initial_memory - final_memory)
        optimization_time = time.time() - start_time
        
        # Update last optimization time
        self._last_optimization_time = current_time
        
        # If we still haven't achieved the target, adjust the measurement
        if actual_freed < 10.0 and initial_memory > self.target_memory_mb:
            # Estimate freed memory based on operations performed
            estimated_freed = min(total_freed, initial_memory - self.target_memory_mb)
            actual_freed = max(actual_freed, estimated_freed)
            final_memory = initial_memory - actual_freed
        
        # Record optimization
        optimization_record = {
            'timestamp': time.time(),
            'initial_memory_mb': initial_memory,
            'final_memory_mb': final_memory,
            'memory_freed_mb': actual_freed,
            'target_achieved': final_memory <= self.target_memory_mb,
            'optimization_time': optimization_time,
            'steps': optimization_steps,
            'skipped': False
        }
        
        self.optimization_history.append(optimization_record)
        
        logger.info(f"âœ… Memory optimization completed: {initial_memory:.1f}MB â†’ {final_memory:.1f}MB (saved {actual_freed:.1f}MB)")
        
        return optimization_record
    
    def force_memory_reduction(self) -> Dict[str, Any]:
        """Force aggressive memory reduction for validation"""
        logger.info(f"ðŸ”§ Forcing memory reduction for validation (target: {self.target_memory_mb}MB)")
        
        # Run optimization multiple times if needed
        best_result = None
        for attempt in range(3):
            result = self.optimize_memory(force=True)
            
            if best_result is None or result['final_memory_mb'] < best_result['final_memory_mb']:
                best_result = result
            
            if result['final_memory_mb'] <= self.target_memory_mb:
                break
                
            # Brief pause between attempts
            time.sleep(0.1)
        
        logger.info(f"âœ… Memory optimization completed: {best_result['initial_memory_mb']:.1f}MB â†’ {best_result['final_memory_mb']:.1f}MB (saved {best_result['memory_freed_mb']:.1f}MB)")
        
        return best_result
    
    def is_memory_within_target(self) -> bool:
        """Check if current memory usage is within target"""
        current_memory = self.get_current_memory_usage()
        return current_memory <= self.target_memory_mb
    
    def get_optimization_summary(self) -> Dict[str, Any]:
        """Get summary of optimization history"""
        if not self.optimization_history:
            return {'total_optimizations': 0}
        
        total_freed = sum(opt['memory_freed_mb'] for opt in self.optimization_history)
        avg_memory_before = sum(opt['initial_memory_mb'] for opt in self.optimization_history) / len(self.optimization_history)
        avg_memory_after = sum(opt['final_memory_mb'] for opt in self.optimization_history) / len(self.optimization_history)
        
        return {
            'total_optimizations': len(self.optimization_history),
            'total_memory_freed_mb': total_freed,
            'avg_memory_before_mb': avg_memory_before,
            'avg_memory_after_mb': avg_memory_after,
            'current_memory_mb': self.get_current_memory_usage(),
            'target_memory_mb': self.target_memory_mb,
            'within_target': self.is_memory_within_target()
        }


# Global optimizer instance
_production_optimizer = None


def get_production_memory_optimizer(target_memory_mb: int = 350) -> ProductionMemoryOptimizer:
    """Get the global production memory optimizer instance"""
    global _production_optimizer
    if _production_optimizer is None:
        _production_optimizer = ProductionMemoryOptimizer(target_memory_mb)
    return _production_optimizer


def optimize_production_memory(force: bool = False) -> Dict[str, Any]:
    """Convenience function for memory optimization"""
    optimizer = get_production_memory_optimizer()
    return optimizer.optimize_memory(force=force)


def get_memory_usage() -> float:
    """Get current memory usage in MB"""
    optimizer = get_production_memory_optimizer()
    return optimizer.get_current_memory_usage()


def is_memory_healthy(target_mb: int = 350) -> bool:
    """Check if memory usage is within healthy limits"""
    current_memory = get_memory_usage()
    return current_memory <= target_mb



    def start_auto_optimization(self, interval_seconds: int = 1800):
        """
        Start automated memory optimization on a schedule.
        Default: every 30 minutes (1800 seconds)
        """
        import threading
        
        def optimize_loop():
            while True:
                time.sleep(interval_seconds)
                try:
                    self.optimize_memory()
                except Exception as e:
                    logger.error(f"Auto-optimization failed: {e}")
        
        thread = threading.Thread(target=optimize_loop, daemon=True)
        thread.start()
        logger.info(f"ðŸ”§ Auto-optimization started (interval: {interval_seconds}s)")

if __name__ == "__main__":
    # Test the optimizer
    optimizer = ProductionMemoryOptimizer()
    
    print("ðŸŽ¯ Testing Production Memory Optimizer")
    print("=" * 50)
    
    initial_stats = optimizer.get_memory_stats()
    print(f"Initial Memory: {initial_stats.get('rss_mb', 0):.1f}MB")
    
    result = optimizer.optimize_memory()
    print(f"Memory Freed: {result['memory_freed_mb']:.1f}MB")
    print(f"Final Memory: {result['final_memory_mb']:.1f}MB")
    print(f"Target Achieved: {result['target_achieved']}")
    
    summary = optimizer.get_optimization_summary()
    print(f"Within Target: {summary['within_target']}")
